# 7015

## Medical Visual Question Answering on VQA-RAD

This repository contains two Med-VQA implementations:

1. CNN-LSTM baseline with frozen ResNet50
2. BLIP-based Vision-Language Model with discriminative fine-tuning

### Dataset
- VQA-RAD
- https://huggingface.co/datasets/flaviagiammarino/vqa-rad/viewer/default/train?p=1&views%5B%5D=train

### Files
- cnn_lstm_vqa.ipynb
- blip_vqa.ipynb

### Environment
- PyTorch
- Transformers
- Kaggle GPU
